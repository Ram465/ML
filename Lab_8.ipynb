{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ram465/ML/blob/main/Lab_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve. Ram Akathya\n",
        "BL.EN.U4CSE21217"
      ],
      "metadata": {
        "id": "o74ecNKVZuY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A1. For the data provided below, calculate the prior probability for each class"
      ],
      "metadata": {
        "id": "XYVIHk1GZyUS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ryr1egTEtQc",
        "outputId": "bbb776c6-8593-4d2c-8e04-14d3254829ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior Probability P(buys_computer = 'no'): 0.364\n",
            "Prior Probability P(buys_computer = 'yes'): 0.636\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load data from Excel file\n",
        "excel_file = \"lab8 dataset.xlsx\"\n",
        "df = pd.read_excel(excel_file)\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "df_encoded = df.apply(label_encoder.fit_transform)\n",
        "\n",
        "# Splitting the data into features and target\n",
        "X = df_encoded.drop('buys_computer', axis=1)  # Make sure to use lowercase 'buys_computer'\n",
        "y = df_encoded['buys_computer']  # Make sure to use lowercase 'buys_computer'\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using Naive Bayes classifier\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "naive_bayes_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Prior probabilities estimated by the classifier\n",
        "prior_probabilities = np.exp(naive_bayes_classifier.class_log_prior_)\n",
        "\n",
        "# Print the results\n",
        "classes = label_encoder.classes_\n",
        "for i, class_label in enumerate(classes):\n",
        "    print(f'Prior Probability P(buys_computer = \\'{class_label}\\'): {prior_probabilities[i]:.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A2. Calculate the class conditional densities for various features & classes. Observe if any class\n",
        "conditional density has zero values."
      ],
      "metadata": {
        "id": "IXalom7cZ2-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "df_encoded = df.apply(label_encoder.fit_transform)\n",
        "\n",
        "# Splitting the data into features and target\n",
        "X = df_encoded.drop('buys_computer', axis=1)\n",
        "y = df_encoded['buys_computer']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using Naive Bayes classifier\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "naive_bayes_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Calculate class conditional densities in log scale\n",
        "log_class_conditional_densities = naive_bayes_classifier.feature_log_prob_\n",
        "\n",
        "# Exponentiate the values to get actual probabilities\n",
        "class_conditional_densities = np.exp(log_class_conditional_densities)\n",
        "\n",
        "# Print the results\n",
        "classes = label_encoder.classes_\n",
        "features = X.columns\n",
        "\n",
        "print(\"Class Conditional Densities:\")\n",
        "for i, class_label in enumerate(classes):\n",
        "    print(f\"\\nClass: {class_label}\")\n",
        "    for j, feature in enumerate(features):\n",
        "        print(f\"Feature: {feature}\")\n",
        "        print(f\"  Class Conditional Density: {class_conditional_densities[i, j]:.3f}\")\n",
        "        if class_conditional_densities[i, j] == 0:\n",
        "            print(f\"  Observation: This class conditional density has a zero value.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXFt2Z5tLswE",
        "outputId": "198f7f51-2358-4c96-b554-391e001ddaa2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Conditional Densities:\n",
            "\n",
            "Class: no\n",
            "Feature: age\n",
            "  Class Conditional Density: 0.412\n",
            "Feature: income\n",
            "  Class Conditional Density: 0.353\n",
            "Feature: student\n",
            "  Class Conditional Density: 0.118\n",
            "Feature: credit_rating\n",
            "  Class Conditional Density: 0.118\n",
            "\n",
            "Class: yes\n",
            "Feature: age\n",
            "  Class Conditional Density: 0.259\n",
            "Feature: income\n",
            "  Class Conditional Density: 0.296\n",
            "Feature: student\n",
            "  Class Conditional Density: 0.222\n",
            "Feature: credit_rating\n",
            "  Class Conditional Density: 0.222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A3. Test for independence between the 4 given features."
      ],
      "metadata": {
        "id": "BKKN1RFQZ8kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create a contingency table\n",
        "contingency_table = pd.crosstab(index=df['age'], columns=[df['income'], df['student'], df['credit_rating']])\n",
        "\n",
        "# Perform the Chi-squared test of independence\n",
        "chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "# Print the results\n",
        "print(\"Chi-squared Statistic:\", chi2_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Check the significance level\n",
        "alpha = 0.05\n",
        "print(\"\\nTest Result:\")\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is evidence of dependence between the variables.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant evidence of dependence between the variables.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZboOZNHN_tN",
        "outputId": "5a08521a-2edd-4c7a-8004-75c6b52cb354"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-squared Statistic: 12.95\n",
            "P-value: 0.6764100579553458\n",
            "\n",
            "Test Result:\n",
            "Fail to reject the null hypothesis. There is no significant evidence of dependence between the variables.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A4. Build a NaÃ¯ve-Bayes (NB) classifier for the above given data. Below code for help.\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "model.fit(Tr_X,Tr_y)"
      ],
      "metadata": {
        "id": "IYqlkj8MZ_aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "X = df.drop('buys_computer', axis=1)\n",
        "y = df['buys_computer']\n",
        "\n",
        "# One-hot encode categorical features\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('encoder', OneHotEncoder(), ['age', 'income', 'student', 'credit_rating'])\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "X_encoded = column_transformer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build Gaussian Naive Bayes classifier\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier (you can use metrics like accuracy, precision, recall, etc.)\n",
        "accuracy = (predictions == y_test).mean()\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "LjKlOieuOgwS",
        "outputId": "16e45646-af59-413e-a620-5a5da7b23ab4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-3e8fab44c903>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Build Gaussian Naive Bayes classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GaussianNB' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A5. Build a NB classifier for your own project data\n"
      ],
      "metadata": {
        "id": "8pmC1SAZaEu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from scipy.stats import chi2_contingency\n",
        "from itertools import product\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = pd.read_excel('/content/embeddingsdata.xlsx')\n",
        "\n",
        "\n",
        "# Separate features and target\n",
        "features = data.iloc[:, :-1]  # Features\n",
        "target = data.iloc[:, -1]      # Target data\n",
        "\n",
        "# Convert categorical data to numerical values using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for col in features.columns:\n",
        "    features[col] = label_encoder.fit_transform(features[col])\n",
        "\n",
        "# Convert features to numeric values\n",
        "features = features.astype(float)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Gaussian Naive Bayes classifier\n",
        "gnb_classifier = GaussianNB()\n",
        "gnb_classifier.fit(features_train, target_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = gnb_classifier.predict(features_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = np.sum(predictions == target_test) / len(target_test)\n",
        "print(f'Accuracy: {accuracy:.2%}')"
      ],
      "metadata": {
        "id": "1OSv5UCOSO0a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}